{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f855792",
   "metadata": {},
   "source": [
    "# Option 2. Finding distance by focal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc01a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch\n",
    "import math\n",
    "import numpy as np \n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import *\n",
    "import shutil\n",
    "import pandas as PD\n",
    "import pillow_heif\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "PD.options.display.expand_frame_repr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf5eefe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-2-19 Python-3.9.7 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6144MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete  (12 CPUs, 32.0 GB RAM, 764.4/919.6 GB disk)\n",
      "Cuda available? True\n",
      "At which number CUDA: 0\n"
     ]
    }
   ],
   "source": [
    "display = utils.notebook_init() \n",
    "print('Cuda available?', torch.cuda.is_available())\n",
    "print('At which number CUDA:', torch.cuda.current_device())\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # without this there will be an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d30f6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function spins the picture depending on what it finds in the file characteristics. \n",
    "def exif_transpose(img):\n",
    "    if not img:\n",
    "        return img\n",
    "    wh = img.size\n",
    "    if wh[0] > wh[1]:\n",
    "        return img\n",
    "    exif_orientation_tag = 274\n",
    "\n",
    "    # Check for EXIF data (only present on some files)\n",
    "    if hasattr(img, \"_getexif\") and isinstance(img._getexif(), dict) and exif_orientation_tag in img._getexif():\n",
    "        exif_data = img._getexif()\n",
    "        orientation = exif_data[exif_orientation_tag]\n",
    "\n",
    "        # Handle EXIF Orientation\n",
    "        if orientation == 1:\n",
    "            # Normal image - nothing to do!\n",
    "            pass\n",
    "        elif orientation == 2:\n",
    "            # Mirrored left to right\n",
    "            img = img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "        elif orientation == 3:\n",
    "            # Rotated 180 degrees\n",
    "            img = img.rotate(180)\n",
    "        elif orientation == 4:\n",
    "            # Mirrored top to bottom\n",
    "            img = img.rotate(180).transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "        elif orientation == 5:\n",
    "            # Mirrored along top-left diagonal\n",
    "            img = img.rotate(-90, expand=True).transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "        elif orientation == 6:\n",
    "            # Rotated 90 degrees\n",
    "            #print('turned')\n",
    "            img = img.rotate(-90, expand=True)\n",
    "        elif orientation == 7:\n",
    "            # Mirrored along top-right diagonal\n",
    "            img = img.rotate(90, expand=True).transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "        elif orientation == 8:\n",
    "            # Rotated 270 degrees\n",
    "            img = img.rotate(90, expand=True)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "444493c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Felix/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirements \"gitpython\" \"tqdm>=4.64.0\" \"setuptools>=65.5.1\" \"wheel>=0.38.0\" not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  Command 'pip install \"gitpython\" \"tqdm>=4.64.0\" \"setuptools>=65.5.1\" \"wheel>=0.38.0\"  ' returned non-zero exit status 1.\n",
      "YOLOv5  2023-2-19 Python-3.9.7 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6144MiB)\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "[Errno 2] No such file or directory: 'my_model\\\\exp4\\\\weights\\\\best.pt'. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDetectMultiBackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautoshape\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# detection model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mautoshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, weights, device, dnn, data, fp16, fuse)\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# PyTorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattempt_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfuse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# model stride\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\experimental.py\u001b[0m in \u001b[0;36mattempt_load\u001b[1;34m(weights, device, inplace, fuse)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mckpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattempt_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mckpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ema'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# FP32 model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_model\\\\exp4\\\\weights\\\\best.pt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattempt_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# arbitrary model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\experimental.py\u001b[0m in \u001b[0;36mattempt_load\u001b[1;34m(weights, device, inplace, fuse)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mckpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattempt_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mckpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ema'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# FP32 model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_model\\\\exp4\\\\weights\\\\best.pt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d6bb9614b356>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#model = torch.hub.load('ultralytics/yolov5', 'custom',  path='runs/train/bw/exp4/weights/last.pt') # works, but loads the BEST every time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ultralytics/yolov5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'custom'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'my_model/exp4/weights/best.pt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# works, but loads every time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ultralytics/yolov5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'custom'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'my_model/points/weights/best.pt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# works, but loads every time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m                                            verbose=verbose, skip_validation=skip_validation)\n\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[1;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[0mentry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhubconf_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py\u001b[0m in \u001b[0;36mcustom\u001b[1;34m(path, autoshape, _verbose, device)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcustom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'path/to/model.pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_verbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;31m# YOLOv5 custom or local model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautoshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_verbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mhelp_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://github.com/ultralytics/yolov5/issues/36'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{e}. Cache may be out of date, try `force_reload=True` or see {help_url} for help.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: [Errno 2] No such file or directory: 'my_model\\\\exp4\\\\weights\\\\best.pt'. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help."
     ]
    }
   ],
   "source": [
    "#model = torch.hub.load('ultralytics/yolov5', 'custom',  path='runs/train/bw/exp4/weights/last.pt') # works, but loads the BEST every time\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom',  path='my_model/exp4/weights/best.pt') # works, but loads every time\n",
    "model2 = torch.hub.load('ultralytics/yolov5', 'custom',  path='my_model/points/weights/best.pt') # works, but loads every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905acab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grayscale2(image):  # reduces the image by a factor of 3\n",
    "    #https://habr.com/ru/post/163663/\n",
    "    #convert image -colorspace gray image\n",
    "    img = Image.open(image).convert('L')\n",
    "    img.save(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432ecfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exif import Image as exif\n",
    "\n",
    "def  get_focus_from_exif(f):\n",
    "    with open(f, \"rb\") as palm_1_file:\n",
    "        palm_1_image = exif(palm_1_file)\n",
    "    if palm_1_image.has_exif:\n",
    "        focal = palm_1_image.get('focal_length_in_35mm_film', 'Unknown')\n",
    "        digital_zoom = palm_1_image.get('digital_zoom_ratio', 'Unknown')  #поиграем с зумом....а нет. зум начинает менять фокусное расстояние и он не нужен, но пусть будет пока.\n",
    "    else:\n",
    "        focal = 0\n",
    "        digital_zoom = 1\n",
    "    \n",
    "    return focal, digital_zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "176d44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert heic_to_jpg. inputs the source file and the path to the new file, returns the path to the new file\n",
    "def conv_heic_to_jpg(file, new_name):\n",
    "\n",
    "    heif_file = pillow_heif.read_heif(file)\n",
    "    image = Image.frombytes(\n",
    "        heif_file.mode,\n",
    "        heif_file.size,\n",
    "        heif_file.data,\n",
    "        \"raw\",\n",
    "    )\n",
    "\n",
    "    ex = heif_file.info['exif']\n",
    "    image.save(new_name, format(\"jpeg\"), exif=ex)\n",
    "    image.close()\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b4c61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recognizing a file and retrieving data from it using a central number\n",
    "def res(file, show_pandas = 0):\n",
    "    if '.heic' in file:\n",
    "        temp_file = 'tmp.jpg'  #нужен временный файл, чтобы не портить датасет\n",
    "        file = conv_heic_to_jpg(work_file, temp_file)\n",
    "    \n",
    "    im = Image.open(file)\n",
    "    (width, height) = im.size\n",
    "    \n",
    "    results = model(file)\n",
    "    pd = results.pandas().xyxy[0]\n",
    " \n",
    "    pd = pd.loc[pd['name'] == 'znak'] # sign table\n",
    "    \n",
    "    # We don't need all the rooms. We only need the one closest to the center\n",
    "\n",
    "    # PROCESSING SIGNS\n",
    "    if show_pandas == 1:\n",
    "        print('Знаки\\n',pd)\n",
    "    \n",
    "    pd = pd.assign(to_centre_x = abs(width/2 - (pd.xmin + (pd.xmax-pd.xmin)/2)))     #consider the distance to the center\n",
    "    pd = pd.assign(centre_x = pd.xmin + (pd.xmax-pd.xmin)/2)                         #we calculate the coordinates of the center \n",
    "    \n",
    "    pd = pd.assign(width = pd.xmax - pd.xmin)                                        #width\n",
    "    pd = pd.assign(height = pd.ymax - pd.ymin)                                       #height\n",
    "    pd = pd.assign(s2 = pd.width * pd.height)                                        #area\n",
    "    \n",
    "    pd = pd.sort_values(['to_centre_x'] )                                            #we sort by proximity to the center. We need the closest number\n",
    "    \n",
    "    \n",
    "    d = dict()   # this dictionary will contain all the results\n",
    "    for index, row in pd.iterrows():\n",
    "        d ['width']  = row['width']\n",
    "        d ['height']  = row['height']\n",
    "        d ['s2']  = row['s2']\n",
    "        d ['xmin']  = row['xmin']\n",
    "        d ['ymin']  = row['ymin']\n",
    "        d ['xmax']  = row['xmax']\n",
    "        d ['ymax']  = row['ymax']\n",
    "        break\n",
    "    # Now in d are all the characteristics of the sign. \n",
    "    \n",
    "    d['im_width'] = width\n",
    "    d['im_height'] = height\n",
    "    \n",
    "    return d    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1f7b5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# procedure cuts out the sign, just to see what is found there. I needed it for debugging.\n",
    "# input a file, and a dictionary with data about the sign\n",
    "# WARNING: it will spoil the file it finds.\n",
    "\n",
    "def crop_znak(temp_file,znak):\n",
    "    if len(znak) <= 3:\n",
    "        #print('не смог кроопнуть', temp_file)\n",
    "        return\n",
    "    img = Image.open(temp_file)\n",
    "    xmin  = znak['xmin']\n",
    "    ymin = znak['ymin']\n",
    "    xmax  = znak['xmax']\n",
    "    ymax  = znak['ymax']\n",
    "    сentre_x = xmin + (xmax-xmin)/2\n",
    "    сentre_y = ymin + (ymax-ymin)/2\n",
    "    w_max = max(xmax-xmin, ymax-ymin)/2\n",
    "    #print((xmin, ymin,xmax, ymax))\n",
    "    img = img.crop((сentre_x-w_max, сentre_y-w_max,сentre_x+w_max, сentre_y+w_max))\n",
    "    img = img.resize((640,640))\n",
    "    print('сохраняем в ',temp_file)\n",
    "    img.save(temp_file)\n",
    "    #считаем коэффициент кроп\n",
    "    k = znak['width']/640\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddc4ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out the area around the sign to feed it back into the network for more accurate recognition. \n",
    "def mini_pic(temp_file,znak):\n",
    "    if len(znak) == 3:\n",
    "        print('не смог кроопнуть', temp_file)\n",
    "        return\n",
    "    if znak['width'] > 400: # only if the sign is very small\n",
    "        return\n",
    "    \n",
    "    img = Image.open(temp_file)\n",
    "    xmin  = znak['xmin']\n",
    "    ymin = znak['ymin']\n",
    "    xmax  = znak['xmax']\n",
    "    ymax  = znak['ymax']\n",
    "    centre_x = xmin + (xmax - xmin)/2\n",
    "    centre_y = ymin + (ymax - ymin)/2\n",
    "    #print((xmin, ymin,xmax, ymax))\n",
    "    img = img.crop((centre_x-480, centre_y - 480,centre_x+480, centre_y + 480))\n",
    "    img.save(temp_file)\n",
    "    #print('минипик',temp_file,centre_x,centre_y, znak['width'])\n",
    "    \n",
    "# try to cut out the area around the sign to feed it back to the network for more accurate recognition.  \n",
    "# This is if the sign in the photo is small and it did not find anything at all. do a cropped center 960x960\n",
    "def zoom960(temp_file):\n",
    "    \n",
    "    img = Image.open(temp_file)\n",
    "    w,h = img.size\n",
    "    centre_x = w//2\n",
    "    centre_y = h//2\n",
    "    img = img.crop((centre_x-480, centre_y - 480,centre_x+480, centre_y + 480))\n",
    "    img.save(temp_file)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bd20af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we correct the sign: depending on the ratio between the found sides we find the angle and use it to calculate what 520 has become\n",
    "    \n",
    "from math import atan, sin, cos, tan,degrees\n",
    "\n",
    "def correct_znak2(znak):\n",
    "    \n",
    "    w_znak = 529 #ширина знака в мм\n",
    "    h_znak = 112\n",
    "    if len(znak) == 3: #похоже, что не рааспознался\n",
    "        return w_znak\n",
    "    #сначала ищем угол наклона знака по соотношению сторон\n",
    "    HW  = 112/520 #стандартное соотношение между сторонами\n",
    "    hw = znak['height']/znak['width']#найденное соотнощение между сторонами\n",
    "    tan_alfa = -(HW - hw) / (1 - HW * hw)\n",
    "    alfa_rad = abs(math.atan(tan_alfa)) #нашли угол наклона знака в радианах\n",
    "    print('приблизительно повернуто',degrees(alfa_rad))\n",
    "    \n",
    "    new_AB = w_znak * cos(alfa_rad) + h_znak * sin(alfa_rad)\n",
    "    #new_w = (CD-AB/tan(alfa_rad)) / (sin(alfa_rad) - cos(alfa_rad)*cos(alfa_rad)/sin(alfa_rad))\n",
    "    \n",
    "    print('корректировка длины знака','520', '---->',new_AB)\n",
    "    \n",
    "    return new_AB\n",
    "\n",
    "\n",
    "#старая версия, она корреткирует не 520, а найденное значение ширины уменьшает.\n",
    "# def correct_znak(znak):\n",
    "#     if len(znak) == 3: #похоже, что не рааспознался\n",
    "#         return znak\n",
    "#     #сначала ищем угол наклона знака по соотношению сторон\n",
    "#     HW  = 112/520 #стандартное соотношение между сторонами\n",
    "#     hw = znak['height']/znak['width']#найденное соотнощение между сторонами\n",
    "#     tan_alfa = -(HW - hw) / (1 - HW * hw)\n",
    "#     alfa_rad = math.atan(tan_alfa) #нашли угол наклона знака в радианах\n",
    "#     print('приблизительно повернуто',degrees(alfa_rad))\n",
    "    \n",
    "#     CD = znak['height']\n",
    "#     AB = znak['width']\n",
    "#     new_w = (CD-AB/tan(alfa_rad)) / (sin(alfa_rad) - cos(alfa_rad)*cos(alfa_rad)/sin(alfa_rad))\n",
    "    \n",
    "#     print('корректировка длины знака',znak['width'], '---->',new_w)\n",
    "#     znak['width'] = new_w\n",
    "#     return znak\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4a35c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS FUNCTION SEARCHES THE DISTANCE BETWEEN TWO fixing points on a number and returns it in pixels\n",
    "\n",
    "def res2(file, show_pandas = 0):\n",
    "#     if '.heic' in file:\n",
    "#         temp_file = 'tmp.jpg'  #нужен временный файл, чтобы не портить датасет\n",
    "#         file = conv_heic_to_jpg(work_file,temp_file)\n",
    "    \n",
    "    im = Image.open(file)\n",
    "    (width, height) = im.size\n",
    "    \n",
    "    results = model2(file)\n",
    "    pd = results.pandas().xyxy[0]\n",
    " \n",
    "    pd = pd.loc[pd['name'] == 'znak']                   # sign table\n",
    "    \n",
    "    #все номера нам не надо. Нам надо только тот, что ближе к центру\n",
    "\n",
    "    #ОБРАБАТЫВАЕМ точки на знаке\n",
    "    if show_pandas == 1:\n",
    "        print('Знаки\\n',pd)\n",
    "    \n",
    "    pd = pd.assign(centre_x = pd.xmin + (pd.xmax-pd.xmin)/2)                         #считаем координаты центра \n",
    "    pd = pd.assign(centre_y = pd.ymin + (pd.ymax-pd.ymin)/2)                         #считаем координаты центра \n",
    "    \n",
    "    pd = pd.assign(width = pd.xmax - pd.xmin)                                        #ширина\n",
    "    pd = pd.assign(height = pd.ymax - pd.ymin)                                       #высота\n",
    "    \n",
    "    pd = pd.loc[pd['centre_y'] >280]\n",
    "    pd = pd.loc[pd['centre_y'] <380]\n",
    "    \n",
    "    pd = pd.sort_values(['centre_x'] )                                            #сортируем по близости к центру. Нам надо самый близкий номер\n",
    "    \n",
    "    if show_pandas == 1:\n",
    "        print('отсортировано\\n',pd)\n",
    "    d = []   #в этом будут две точки, нам надо найти расстояние между ними\n",
    "    for index, row in pd.iterrows():\n",
    "        d.append([row['centre_x'],row['centre_y']])\n",
    "    if len(d) == 2:\n",
    "        r = ((d[0][0] - d[1][0])**2 + (d[0][1] - d[1][1])**2) **0.5\n",
    "    else:\n",
    "        r = 0\n",
    "         \n",
    "    if show_pandas == 1:\n",
    "        print('Расстояние', r)\n",
    "    \n",
    "    return r    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3732feda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Знаки\n",
      "          xmin        ymin        xmax        ymax  confidence  class  name\n",
      "0  614.981262  300.257507  627.810974  313.202515    0.737279      0  znak\n",
      "1   14.071442  325.275391   27.708603  339.688538    0.722411      0  znak\n",
      "отсортировано\n",
      "          xmin        ymin        xmax        ymax  confidence  ...  name    centre_x    centre_y      width     height\n",
      "1   14.071442  325.275391   27.708603  339.688538    0.722411  ...  znak   20.890022  332.481964  13.637161  14.413147\n",
      "0  614.981262  300.257507  627.810974  313.202515    0.737279  ...  znak  621.396118  306.730011  12.829712  12.945007\n",
      "\n",
      "[2 rows x 11 columns]\n",
      "Расстояние 601.0580124133401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "601.0580124133401"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2('Y:\\\\img_1931.jpg',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6d2be301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_recognition(f):\n",
    "    w_znak = 520 #ширина знака в мм\n",
    "    #w = 4032    #разрешение матрицы/фото в пикселях\n",
    "    \n",
    "    name = f[f.rfind('/')+1:]\n",
    "    work_file = f\n",
    "    temp_file = 'temp.jpg'\n",
    "    #temp_file = 'Y:/'+name\n",
    "    if '.heic' in f:\n",
    "        temp_file = 'Y:/'+name.replace('.heic','.jpg')\n",
    "        print('Новое имя',temp_file)\n",
    "        work_file = conv_heic_to_jpg(work_file,temp_file)\n",
    "        #print('Сконвертирован в',work_file)\n",
    "    focus, digital_zoom = get_focus_from_exif(work_file)\n",
    "    print('focus, digital_zoom',focus, digital_zoom)\n",
    "     \n",
    "    img = Image.open(work_file)\n",
    "    img = exif_transpose(img)\n",
    "    w,h = img.size\n",
    "    img.save(temp_file)\n",
    "    \n",
    "    img.close()\n",
    "\n",
    "    #get_grayscale2(temp_file)  #пытался работать с серым. не очень.\n",
    "    \n",
    "    znak1 = res(temp_file)\n",
    "    znak = znak1\n",
    "    \n",
    "#     #Заходим еще 1 раз, если ничего не нашли. просто на удачу\n",
    "#     if len(znak) <= 3:\n",
    "#         zoom960(temp_file)\n",
    "#         znak1 = res(temp_file)\n",
    "#         znak = znak1\n",
    "        \n",
    "    \n",
    "    \n",
    "    #ЭКСПЕРИМЕНТ\n",
    "#     if len(znak1) <= 3:\n",
    "#         print('ФАЙЛ НЕ РАСПОЗНАН', f)\n",
    "#         not_recognize.append(f) \n",
    "#         return 0.0\n",
    "    \n",
    "#     #пробуем вырезать область,чтобы знак был бллиже. количество пикселей от этого не меняется\n",
    "#     print('ширина до мини пика', znak1['width'])\n",
    "\n",
    "#     mini_pic(temp_file,znak1)\n",
    "#     #вырезали и еще раз на распознавание\n",
    "#     znak = res(temp_file)\n",
    "#     if len(znak) != 3:\n",
    "#         print('ширина после мини пика', znak['width'], 'уточнение', znak1['width']-znak['width'])\n",
    "#     else: #почему то после зума, знак не распознался. Возвращаем то, что было, это всяко лучше чем ноль\n",
    "#         znak = znak1\n",
    "        \n",
    "    #....конец эксперимента.\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    w_matrix = 35# 34.974 #ширина матрицы в мм. Вроде бы именнь это классическая ширина, но ее в разговоре просто округляют до 35 мм.\n",
    "    #print('ширина кадра',w)\n",
    "    pixel_in_mm = w/w_matrix\n",
    "    d1 = 0\n",
    "    if 'width' in znak:\n",
    "        k = crop_znak(temp_file,znak)  #коэффикиент кропа\n",
    "        r = res2(temp_file) #получили расстояние между двумя точками на номере \n",
    "        print('r,k',r* k,znak['width'])\n",
    "        if r!=0:\n",
    "            r = r * k #привели к нормальной ширине\n",
    "            #print(r)\n",
    "            d1 = (1 + 487 /(r/pixel_in_mm))* focus/1000\n",
    "            print('расстояние по точкам', d1)\n",
    "            return d1 #если есть расстояние между точками - за ним преимущество\n",
    "    \n",
    "    \n",
    "    if len(znak) <= 3:\n",
    "        print('ФАЙЛ НЕ РАСПОЗНАН', f)\n",
    "        not_recognize.append(f)\n",
    "        d = 0.0\n",
    "    #формируем строку с параметрами знака для записи в csv\n",
    "    else:\n",
    "         #уточнение полученнного расстояние\n",
    "        w_znak = correct_znak2(znak)\n",
    "        d = (1 + w_znak /(znak['width']/pixel_in_mm))* focus/1000  #ну вот тут я заморочился. не мог решить до чего считать расстояние - до оптического центра или до матрицы. Стал считать до матрицы. Объектив может гулять от матрицы на много см.\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6208c8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381 работаем  с файлом:  ..\\data_set\\test\\img_2674.heic\n",
      "Новое имя Y:\\img_2674.jpg\n",
      "focus, digital_zoom 14 1.0327868852459017\n",
      "ФАЙЛ НЕ РАСПОЗНАН ..\\data_set\\test\\img_2674.heic\n",
      "Записан результат:  img_2674.heic;0.0\n",
      "\n",
      "\n",
      "\n",
      "382 работаем  с файлом:  ..\\data_set\\test\\img_2675.jpg\n",
      "focus, digital_zoom 14 1.0223123732251522\n",
      "сохраняем в  temp.jpg\n",
      "r,k 148.69137140255333 158.6239013671875\n",
      "расстояние по точкам 5.296307860848156\n",
      "Записан результат:  img_2675.jpg;5.296307860848156\n",
      "\n",
      "\n",
      "\n",
      "383 работаем  с файлом:  ..\\data_set\\test\\img_2676.jpg\n",
      "focus, digital_zoom 14 1.0223123732251522\n",
      "сохраняем в  temp.jpg\n",
      "r,k 189.8632736006027 206.633056640625\n",
      "расстояние по точкам 4.150837973478968\n",
      "Записан результат:  img_2676.jpg;4.150837973478968\n",
      "\n",
      "\n",
      "\n",
      "384 работаем  с файлом:  ..\\data_set\\test\\img_2677.heic\n",
      "Новое имя Y:\\img_2677.jpg\n",
      "focus, digital_zoom 14 1.0327868852459017\n",
      "сохраняем в  Y:\\img_2677.jpg\n",
      "r,k 139.3193845650131 157.6392822265625\n",
      "расстояние по точкам 5.651647642876854\n",
      "Записан результат:  img_2677.heic;5.651647642876854\n",
      "\n",
      "\n",
      "\n",
      "385 работаем  с файлом:  ..\\data_set\\test\\img_2677.jpg\n",
      "focus, digital_zoom 14 1.0223123732251522\n",
      "сохраняем в  temp.jpg\n",
      "r,k 225.94761113157276 239.9176025390625\n",
      "расстояние по точкам 3.490175720851636\n",
      "Записан результат:  img_2677.jpg;3.490175720851636\n",
      "\n",
      "\n",
      "\n",
      "не распознано файлов 1\n",
      "не распознанные ..\\data_set\\test\\img_2674.heic\n",
      "сохранено в  ..\\data_set\\sample_solution.csv\n",
      "Ошибка не посчитана. Истинных данных не обнаружено. Датасет тестовый?\n"
     ]
    }
   ],
   "source": [
    "train_csv = '../data_set/train.csv'  #data set if you run it on a training dataset, it will be considered an error.\n",
    "keys = ['width', 'height', 's2', 'xmin', 'ymin', 'xmax', 'ymax','im_width', 'im_height']\n",
    "pic_data = '../data_set/train'  # here is the dataset\n",
    "pic_data_test  = pic_data\n",
    "\n",
    "# TO RUN ON YOUR DATASET, YOU NEED TO CHANGE THIS PATH\n",
    "pic_data_test = '../data_set/test'  # Here is the test dataset\n",
    "\n",
    "\n",
    "test = '../data_set/sample_solution.csv'  # the result will be recorded here\n",
    "\n",
    "# first read all the distances given to us from the training dataset\n",
    "dist = dict()  # here we will store all distances extracted from the file. In the form of a dictionary\n",
    "with open(train_csv, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.replace('\\n','')\n",
    "        key, d = line.split(';')\n",
    "        dist[key] = d\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "new_f = 'image_name;distance'\n",
    "not_recognize = []  # there will be some unrecognized\n",
    "n = 0\n",
    "abs_mistake, otn_mistake, vsego = 0, 0, 0  # To calculate the error\n",
    "for f in os.listdir(pic_data_test):\n",
    "    n +=1\n",
    "    if n<= 380:\n",
    "        continue\n",
    "    if n>385:\n",
    "         break\n",
    "    \n",
    "    \n",
    "    work_file = os.path.join(pic_data_test, f)\n",
    "    print(n, 'working with the file: ', work_file)\n",
    "\n",
    "    itog = file_recognition(work_file)\n",
    "    \n",
    "    # we get the true value, count the error\n",
    "    if f in dist:\n",
    "        y = float(dist[f])\n",
    "        mistake = (y - itog) / y # I apologize for not using your mistake, but it makes more sense to me in percentages, and since I don't train on a mistake, I did so.\n",
    "        print('Error', mistake, 'estimation', y, 'предск', itog)\n",
    "        otn_mistake += mistake  #you need it to see if it goes in the plus or minus\n",
    "        abs_mistake += abs(mistake)\n",
    "        vsego +=1\n",
    "    \n",
    "    \n",
    "    st = f+';' + str(itog)\n",
    "    print('Recorded result: ',st)\n",
    "    print('\\n\\n')    \n",
    "    new_f = new_f +'\\n'+st\n",
    "    \n",
    "#print(new_f)\n",
    "with open(test, 'w', encoding = 'utf-8') as file:\n",
    "    file.write(new_f)\n",
    "print('Nr of files not detected:', len(not_recognize))\n",
    "print('unrecognized:', *not_recognize)\n",
    "print('saved in:', test)\n",
    "if vsego != 0:\n",
    "    print('Аbsolute error', round(abs_mistake/vsego*100, 5))\n",
    "    print('Relative error', round(otn_mistake/vsego*100, 5))\n",
    "else:\n",
    "    print('No error has been calculated. No true data detected. Is the dataset a test one?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52c48a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Знаки\n",
      "           xmin         ymin         xmax         ymax  confidence  class  name\n",
      "0  1760.632202  1313.192139  2381.237305  1438.997437    0.952805      0  znak\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'width': 620.6051025390625,\n",
       " 'height': 125.8052978515625,\n",
       " 's2': 78075.40977312624,\n",
       " 'xmin': 1760.6322021484375,\n",
       " 'ymin': 1313.192138671875,\n",
       " 'xmax': 2381.2373046875,\n",
       " 'ymax': 1438.9974365234375,\n",
       " 'im_width': 3968,\n",
       " 'im_height': 2976}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res('Y:\\\\255_1.jpg',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2dce39d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Новое имя Y:\\img_2674.jpg\n",
      "focus, digital_zoom 14 1.0327868852459017\n",
      "ФАЙЛ НЕ РАСПОЗНАН ..\\data_set\\test\\img_2674.heic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_recognition('..\\\\data_set\\\\test\\\\img_2674.heic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "37db3b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "focus, digital_zoom 27 1.0\n",
      "сохраняем в  temp.jpg\n",
      "r,k 592.7320572254057 619.9266357421875\n",
      "расстояние по точкам 2.5419996463221812\n",
      "2.5419996463221812\n",
      "\n",
      "\n",
      "focus, digital_zoom 31 1.0\n",
      "сохраняем в  temp.jpg\n",
      "r,k 718.0005061784991 743.150390625\n",
      "расстояние по точкам 2.414798399046464\n",
      "2.414798399046464\n",
      "\n",
      "\n",
      "focus, digital_zoom 52 1.0\n",
      "сохраняем в  temp.jpg\n",
      "r,k 1166.430252539312 1251.6114501953125\n",
      "расстояние по точкам 2.513371394382705\n",
      "2.513371394382705\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(file_recognition('Y:\\\\255_1.jpg'))\n",
    "\n",
    "print('\\n')\n",
    "print(file_recognition('Y:\\\\255_2.jpg'))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(file_recognition('Y:\\\\255_3.jpg'))\n",
    "\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fc2c2ae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Y:\\\\421_1.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [160]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfile_recognition\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mY:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m421_1.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(file_recognition(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m421_2.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Input \u001b[1;32mIn [154]\u001b[0m, in \u001b[0;36mfile_recognition\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m     12\u001b[0m     work_file \u001b[38;5;241m=\u001b[39m conv_heic_to_jpg(work_file,temp_file)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m#print('Сконвертирован в',work_file)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m focus, digital_zoom \u001b[38;5;241m=\u001b[39m \u001b[43mget_focus_from_exif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwork_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfocus, digital_zoom\u001b[39m\u001b[38;5;124m'\u001b[39m,focus, digital_zoom)\n\u001b[0;32m     17\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(work_file)\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mget_focus_from_exif\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m  \u001b[38;5;21mget_focus_from_exif\u001b[39m(f):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m palm_1_file:\n\u001b[0;32m      4\u001b[0m         palm_1_image \u001b[38;5;241m=\u001b[39m exif(palm_1_file)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m palm_1_image\u001b[38;5;241m.\u001b[39mhas_exif:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Y:\\\\421_1.jpg'"
     ]
    }
   ],
   "source": [
    "print(file_recognition('Y:\\\\421_1.jpg'))\n",
    "print('\\n')\n",
    "print(file_recognition('Y:\\\\421_2.jpg'))\n",
    "print('\\n')\n",
    "\n",
    "print(file_recognition('Y:\\\\421_3.jpg'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "524a3cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.923146672370446\n",
      "\n",
      "\n",
      "4.690990338609638\n",
      "\n",
      "\n",
      "4.974977451052313\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(file_recognition('Y:\\\\490_1.jpg'))\n",
    "print('\\n')\n",
    "print(file_recognition('Y:\\\\490_2.jpg'))\n",
    "print('\\n')\n",
    "\n",
    "print(file_recognition('Y:\\\\490_3.jpg'))\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
