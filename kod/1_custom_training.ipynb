{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316138b5",
   "metadata": {},
   "source": [
    "# Training YOLOv5\n",
    "\n",
    "Copied/Adapted from https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb#scrollTo=15glLzbQx5u0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf1ae5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06888e00-708a-4b5e-9430-d88c69557f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  # clone\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d798521",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2023-2-18 Python-3.10.9 torch-1.13.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete âœ… (64 CPUs, 125.7 GB RAM, 540.5/6883.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a9d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "062db77b",
   "metadata": {},
   "source": [
    "## 1. Detect\n",
    "\n",
    "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
    "\n",
    "```shell\n",
    "python detect.py --source 0  # webcam\n",
    "                          img.jpg  # image \n",
    "                          vid.mp4  # video\n",
    "                          screen  # screenshot\n",
    "                          path/  # directory\n",
    "                         'path/*.jpg'  # glob\n",
    "                         'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
    "                         'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6166d69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/car-distance-ptod/kod/detect.py\", line 42, in <module>\n",
      "    from models.common import DetectMultiBackend\n",
      "  File \"/home/jovyan/car-distance-ptod/kod/models/common.py\", line 16, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/__init__.py\", line 48, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/api.py\", line 47, in <module>\n",
      "    from pandas.core.groupby import (\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/groupby/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.groupby.generic import (\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/groupby/generic.py\", line 76, in <module>\n",
      "    from pandas.core.frame import DataFrame\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py\", line 172, in <module>\n",
      "    from pandas.core.generic import NDFrame\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py\", line 169, in <module>\n",
      "    from pandas.core.window import (\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/window/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.window.ewm import (\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/window/ewm.py\", line 15, in <module>\n",
      "    import pandas._libs.window.aggregations as window_aggregations\n",
      "ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /opt/conda/lib/python3.10/site-packages/pandas/_libs/window/aggregations.cpython-310-x86_64-linux-gnu.so)\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images\n",
    "# display.Image(filename='runs/detect/exp/zidane.jpg', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaacdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "499a08d8",
   "metadata": {},
   "source": [
    "## 2. Validate\n",
    "Validate a model's accuracy on the [COCO](https://cocodataset.org/#home) dataset's `val` or `test` splits. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef2f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download COCO val\n",
    "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
    "!unzip -q tmp.zip -d ../datasets && rm tmp.zip  # unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab5da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate YOLOv5s on COCO val\n",
    "!python val.py --weights yolov5s.pt --data coco.yaml --img 640 --half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176fab36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "826ec2f6",
   "metadata": {},
   "source": [
    "# 3. Train\n",
    "\n",
    "<p align=\"\"><a href=\"https://roboflow.com/?ref=ultralytics\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/im/integrations-loop.png\"/></a></p>\n",
    "Close the active learning loop by sampling images from your inference conditions with the `roboflow` pip package\n",
    "<br><br>\n",
    "\n",
    "Train a YOLOv5s model on the [COCO128](https://www.kaggle.com/ultralytics/coco128) dataset with `--data coco128.yaml`, starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`.\n",
    "\n",
    "- **Pretrained [Models](https://github.com/ultralytics/yolov5/tree/master/models)** are downloaded\n",
    "automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases)\n",
    "- **[Datasets](https://github.com/ultralytics/yolov5/tree/master/data)** available for autodownload include: [COCO](https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml), [COCO128](https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml), [VOC](https://github.com/ultralytics/yolov5/blob/master/data/VOC.yaml), [Argoverse](https://github.com/ultralytics/yolov5/blob/master/data/Argoverse.yaml), [VisDrone](https://github.com/ultralytics/yolov5/blob/master/data/VisDrone.yaml), [GlobalWheat](https://github.com/ultralytics/yolov5/blob/master/data/GlobalWheat2020.yaml), [xView](https://github.com/ultralytics/yolov5/blob/master/data/xView.yaml), [Objects365](https://github.com/ultralytics/yolov5/blob/master/data/Objects365.yaml), [SKU-110K](https://github.com/ultralytics/yolov5/blob/master/data/SKU-110K.yaml).\n",
    "- **Training Results** are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n",
    "<br><br>\n",
    "\n",
    "A **Mosaic Dataloader** is used for training which combines 4 images into 1 mosaic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dafdea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "211ee514",
   "metadata": {},
   "source": [
    "### Select YOLOv5 logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebffb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Select YOLOv5 ðŸš€ logger {run: 'auto'}\n",
    "logger = 'ClearML' #@param ['ClearML', 'Comet', 'TensorBoard']\n",
    "\n",
    "if logger == 'ClearML':\n",
    "    %pip install -q clearml\n",
    "    import clearml; clearml.browser_login()\n",
    "elif logger == 'Comet':\n",
    "    %pip install -q comet_ml\n",
    "    import comet_ml; comet_ml.init()\n",
    "elif logger == 'TensorBoard':\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir runs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6efc51f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/car-distance-ptod/kod/train.py\", line 42, in <module>\n",
      "    import val as validate  # for end-of-epoch mAP\n",
      "  File \"/home/jovyan/car-distance-ptod/kod/val.py\", line 37, in <module>\n",
      "    from models.common import DetectMultiBackend\n",
      "  File \"/home/jovyan/car-distance-ptod/kod/models/common.py\", line 16, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/__init__.py\", line 48, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/api.py\", line 47, in <module>\n",
      "    from pandas.core.groupby import (\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/groupby/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.groupby.generic import (\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/groupby/generic.py\", line 76, in <module>\n",
      "    from pandas.core.frame import DataFrame\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py\", line 172, in <module>\n",
      "    from pandas.core.generic import NDFrame\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py\", line 169, in <module>\n",
      "    from pandas.core.window import (\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/window/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.window.ewm import (\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/core/window/ewm.py\", line 15, in <module>\n",
      "    import pandas._libs.window.aggregations as window_aggregations\n",
      "ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /opt/conda/lib/python3.10/site-packages/pandas/_libs/window/aggregations.cpython-310-x86_64-linux-gnu.so)\n"
     ]
    }
   ],
   "source": [
    "# Train YOLOv5s on COCO128 for 3 epochs\n",
    "!python train.py --img 640 --batch 16 --epochs 2 --data plates.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd6d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6d634e6",
   "metadata": {},
   "source": [
    "## 4. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef080e3f",
   "metadata": {},
   "source": [
    "### ClearML Logging and Automation ðŸŒŸ NEW\n",
    "\n",
    "[ClearML](https://cutt.ly/yolov5-notebook-clearml) is completely integrated into YOLOv5 to track your experimentation, manage dataset versions and even remotely execute training runs. To enable ClearML (check cells above):\n",
    "\n",
    "- `pip install clearml`\n",
    "- run `clearml-init` to connect to a ClearML server (**deploy your own [open-source server](https://github.com/allegroai/clearml-server)**, or use our [free hosted server](https://cutt.ly/yolov5-notebook-clearml))\n",
    "\n",
    "You'll get all the great expected features from an experiment manager: live updates, model upload, experiment comparison etc. but ClearML also tracks uncommitted changes and installed packages for example. Thanks to that ClearML Tasks (which is what we call experiments) are also reproducible on different machines! With only 1 extra line, we can schedule a YOLOv5 training task on a queue to be executed by any number of ClearML Agents (workers).\n",
    "\n",
    "You can use ClearML Data to version your dataset and then pass it to YOLOv5 simply using its unique ID. This will help you keep track of your data without adding extra hassle. Explore the [ClearML Tutorial](https://github.com/ultralytics/yolov5/tree/master/utils/loggers/clearml) for details!\n",
    "\n",
    "<a href=\"https://cutt.ly/yolov5-notebook-clearml\">\n",
    "<img alt=\"ClearML Experiment Management UI\" src=\"https://github.com/thepycoder/clearml_screenshots/raw/main/scalars.jpg\" width=\"1280\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e3612",
   "metadata": {},
   "source": [
    "### Local Logging\n",
    "\n",
    "Training results are automatically logged with [Tensorboard](https://www.tensorflow.org/tensorboard) and [CSV](https://github.com/ultralytics/yolov5/pull/4148) loggers to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, etc.\n",
    "\n",
    "This directory contains train and val statistics, mosaics, labels, predictions and augmentated mosaics, as well as metrics and charts including precision-recall (PR) curves and confusion matrices. \n",
    "\n",
    "<img alt=\"Local logging results\" src=\"https://user-images.githubusercontent.com/26833433/183222430-e1abd1b7-782c-4cde-b04d-ad52926bf818.jpg\" width=\"1280\"/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
