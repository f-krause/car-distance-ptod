{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a56e68b",
   "metadata": {},
   "source": [
    "# Option 2. Finding distance by focal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c5956f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch\n",
    "import math\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import *\n",
    "import shutil\n",
    "import pandas as PD\n",
    "import pillow_heif\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "PD.options.display.expand_frame_repr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7852556",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 üöÄ 2023-2-27 Python-3.10.9 torch-1.13.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ‚úÖ (64 CPUs, 125.7 GB RAM, 540.5/6883.7 GB disk)\n",
      "Cuda available? True\n",
      "At which number CUDA: 0\n"
     ]
    }
   ],
   "source": [
    "display = utils.notebook_init() \n",
    "print('Cuda available?', torch.cuda.is_available())\n",
    "print('At which number CUDA:', torch.cuda.current_device())\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # without this there will be an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6762aeb1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=300, batch_size=16, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m tqdm>=4.64.0 not found and is required by YOLOv5, attempting auto-update...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting tqdm>=4.64.0\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.61.2\n",
      "    Uninstalling tqdm-4.61.2:\n",
      "      Successfully uninstalled tqdm-4.61.2\n",
      "Successfully installed tqdm-4.64.1\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m thop>=0.1.1 not found and is required by YOLOv5, attempting auto-update...\n",
      "Collecting thop>=0.1.1\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from thop>=0.1.1) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.8/site-packages (from torch->thop>=0.1.1) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->thop>=0.1.1) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.8/site-packages (from torch->thop>=0.1.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.8/site-packages (from torch->thop>=0.1.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.8/site-packages (from torch->thop>=0.1.1) (11.10.3.66)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->thop>=0.1.1) (0.36.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->thop>=0.1.1) (49.6.0.post20210108)\n",
      "Installing collected packages: thop\n",
      "Successfully installed thop-0.1.1.post2209072238\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 2 packages updated per /home/jovyan/car-distance-ptod/kod/requirements.txt\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "YOLOv5 üöÄ 2023-2-18 Python-3.8.8 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3090, 24268MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs in Weights & Biases\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2023-02-19 17:51:56.819808: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-19 17:51:57.687020: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-19 17:51:57.687101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-19 17:51:57.687109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\n",
      "Dataset not found ‚ö†Ô∏è, missing paths ['/home/jovyan/car-distance-ptod/datasets/coco128/images/train2017']\n",
      "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5116388a21a249f59c4409e2eae1100c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/6.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset download success ‚úÖ (0.9s), saved to \u001b[1m/home/jovyan/car-distance-ptod/datasets\u001b[0m\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to /home/jovyan/.config/Ultralytics/Arial.ttf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ccf782ac4449208b07ffaa79ebf6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/755k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5m.pt to yolov5m.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7d12bfa0304f8aa67155da406fa8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/40.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1    343485  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 369 layers, 21190557 parameters, 21190557 gradients\n",
      "\n",
      "Transferred 481/481 items from yolov5m.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/jovyan/car-distance-ptod/datasets/coco128/labels/train2017' images and labels...126 found, 2 missing, 0 empty, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<00:00, 4263.01it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/jovyan/car-distance-ptod/datasets/coco128/labels/train2017.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/jovyan/car-distance-ptod/datasets/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.96 anchors/target, 0.957 Best Possible Recall (BPR). Anchors are a poor fit to dataset ‚ö†Ô∏è, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING: Extremely small objects found: 35 of 929 labels are < 3 pixels in size\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 927 points...\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.6576:  22%|‚ñà‚ñà‚ñè       | 221/1000 [00:00<00:00, 2202.07it/s]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 366, in reduce_storage\n",
      "    fd, size = storage._share_fd_cpu_()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 366, in reduce_storage\n",
      "    fd, size = storage._share_fd_cpu_()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 366, in reduce_storage\n",
      "    fd, size = storage._share_fd_cpu_()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 366, in reduce_storage\n",
      "    fd, size = storage._share_fd_cpu_()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 366, in reduce_storage\n",
      "    fd, size = storage._share_fd_cpu_()\n",
      "RuntimeError: unable to write to file </torch_13284_2646821132_2>: No space left on device (28)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 366, in reduce_storage\n",
      "    fd, size = storage._share_fd_cpu_()\n",
      "RuntimeError: unable to write to file </torch_13880_3425123983_0>: No space left on device (28)\n",
      "RuntimeError: unable to write to file </torch_13879_2206801107_0>: No space left on device (28)\n",
      "RuntimeError: unable to write to file </torch_13348_660058622_2>: No space left on device (28)\n",
      "RuntimeError: unable to write to file </torch_13868_646860307_1>: No space left on device (28)\n",
      "RuntimeError: unable to write to file </torch_13871_102254767_0>: No space left on device (28)\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.6607:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 443/1000 [00:00<00:00, 2204.06it/s]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 366, in reduce_storage\n",
      "    fd, size = storage._share_fd_cpu_()\n",
      "RuntimeError: unable to write to file </torch_13879_2995521583_1>: No space left on device (28)\n",
      "ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.6612:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 638/1000 [00:00<00:00, 2406.98it/s]\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mERROR: DataLoader worker (pid 13880) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.\n",
      "ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 366, in reduce_storage\n",
      "    fd, size = storage._share_fd_cpu_()\n",
      "RuntimeError: unable to write to file </torch_13898_2731805455_2>: No space left on device (28)\n",
      "ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_13147/1345652064.py\", line 3, in <module>\n",
      "    train.run(data='coco128.yaml', imgsz=320, weights='yolov5m.pt')\n",
      "  File \"/home/jovyan/car-distance-ptod/kod/train.py\", line 624, in run\n",
      "    main(opt)\n",
      "  File \"/home/jovyan/car-distance-ptod/kod/train.py\", line 526, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"/home/jovyan/car-distance-ptod/kod/train.py\", line 222, in train\n",
      "    check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)  # run AutoAnchor\n",
      "  File \"/home/jovyan/car-distance-ptod/kod/utils/autoanchor.py\", line 56, in check_anchors\n",
      "    new_bpr = metric(anchors)[0]\n",
      "  File \"/home/jovyan/car-distance-ptod/kod/utils/autoanchor.py\", line 36, in metric\n",
      "    r = wh[:, None] / k[None]\n",
      "RuntimeError: The size of tensor a (929) must match the size of tensor b (3) at non-singleton dimension 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/lib/python3.8/posixpath.py\", line 424, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/opt/conda/lib/python3.8/posixpath.py\", line 85, in join\n",
      "    elif not path or path.endswith(sep):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 13604) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13147/1345652064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coco128.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'yolov5m.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/car-distance-ptod/kod/train.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/car-distance-ptod/kod/train.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(opt, callbacks)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevolve\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/car-distance-ptod/kod/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(hyp, opt, device, callbacks)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoautoanchor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0mcheck_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'anchor_t'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run AutoAnchor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pre-reduce anchor precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/car-distance-ptod/kod/utils/autoanchor.py\u001b[0m in \u001b[0;36mcheck_anchors\u001b[0;34m(dataset, model, thr, imgsz)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{PREFIX}ERROR: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mnew_bpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_bpr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbpr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# replace anchors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/car-distance-ptod/kod/utils/autoanchor.py\u001b[0m in \u001b[0;36mmetric\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# compute metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# ratio metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (929) must match the size of tensor b (3) at non-singleton dimension 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RuntimeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "import train\n",
    "train.run(data='coco128.yaml', imgsz=320, weights='yolov5m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20de670",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/ultralytics_yolov5_master\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'scale_boxes' from 'utils.general' (/home/jovyan/car-distance-ptod/kod/utils/general.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#model = torch.hub.load('ultralytics/yolov5', 'custom',  path='runs/train/bw/exp4/weights/last.pt') # works, but loads the BEST every time\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43multralytics/yolov5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcustom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmy_model/exp4/weights/best.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# works, but loads every time\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124multralytics/yolov5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m'\u001b[39m,  path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_model/points/weights/best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# works, but loads every time\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/hub.py:542\u001b[0m, in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgithub\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    539\u001b[0m     repo_or_dir \u001b[38;5;241m=\u001b[39m _get_cache_or_reload(repo_or_dir, force_reload, trust_repo, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    540\u001b[0m                                        verbose\u001b[38;5;241m=\u001b[39mverbose, skip_validation\u001b[38;5;241m=\u001b[39mskip_validation)\n\u001b[0;32m--> 542\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_or_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/hub.py:572\u001b[0m, in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m hub_module \u001b[38;5;241m=\u001b[39m _import_module(MODULE_HUBCONF, hubconf_path)\n\u001b[1;32m    571\u001b[0m entry \u001b[38;5;241m=\u001b[39m _load_entry_from_hubconf(hub_module, model)\n\u001b[0;32m--> 572\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mentry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mremove(hubconf_dir)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py:83\u001b[0m, in \u001b[0;36mcustom\u001b[0;34m(path, autoshape, _verbose, device)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom\u001b[39m(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath/to/model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, autoshape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# YOLOv5 custom or local model\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_verbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py:33\u001b[0m, in \u001b[0;36m_create\u001b[0;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates or loads a YOLOv5 model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    YOLOv5 model\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoShape, DetectMultiBackend\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attempt_load\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01myolo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassificationModel, DetectionModel, SegmentationModel\n",
      "File \u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TryExcept\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exif_transpose, letterbox\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (LOGGER, ROOT, Profile, check_requirements, check_suffix, check_version, colorstr,\n\u001b[1;32m     31\u001b[0m                            increment_path, is_notebook, make_divisible, non_max_suppression, scale_boxes, xywh2xyxy,\n\u001b[1;32m     32\u001b[0m                            xyxy2xywh, yaml_load)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Annotator, colors, save_one_box\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy_attr, smart_inference_mode\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'scale_boxes' from 'utils.general' (/home/jovyan/car-distance-ptod/kod/utils/general.py)"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "#model = torch.hub.load('ultralytics/yolov5', 'custom',  path='runs/train/bw/exp4/weights/last.pt') # works, but loads the BEST every time\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom',  path='my_model/exp4/weights/best.pt') # works, but loads every time\n",
    "model2 = torch.hub.load('ultralytics/yolov5', 'custom',  path='my_model/points/weights/best.pt') # works, but loads every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fb8fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function spins the picture depending on what it finds in the file characteristics. \n",
    "def exif_transpose(img):\n",
    "    if not img:\n",
    "        return img\n",
    "    wh = img.size\n",
    "    if wh[0] > wh[1]:\n",
    "        return img\n",
    "    exif_orientation_tag = 274\n",
    "\n",
    "    # Check for EXIF data (only present on some files)\n",
    "    if hasattr(img, \"_getexif\") and isinstance(img._getexif(), dict) and exif_orientation_tag in img._getexif():\n",
    "        exif_data = img._getexif()\n",
    "        orientation = exif_data[exif_orientation_tag]\n",
    "\n",
    "        # Handle EXIF Orientation\n",
    "        if orientation == 1:\n",
    "            # Normal image - nothing to do!\n",
    "            pass\n",
    "        elif orientation == 2:\n",
    "            # Mirrored left to right\n",
    "            img = img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "        elif orientation == 3:\n",
    "            # Rotated 180 degrees\n",
    "            img = img.rotate(180)\n",
    "        elif orientation == 4:\n",
    "            # Mirrored top to bottom\n",
    "            img = img.rotate(180).transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "        elif orientation == 5:\n",
    "            # Mirrored along top-left diagonal\n",
    "            img = img.rotate(-90, expand=True).transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "        elif orientation == 6:\n",
    "            # Rotated 90 degrees\n",
    "            #print('turned')\n",
    "            img = img.rotate(-90, expand=True)\n",
    "        elif orientation == 7:\n",
    "            # Mirrored along top-right diagonal\n",
    "            img = img.rotate(90, expand=True).transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "        elif orientation == 8:\n",
    "            # Rotated 270 degrees\n",
    "            img = img.rotate(90, expand=True)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "789c0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grayscale2(image):  # reduces the image by a factor of 3\n",
    "    #https://habr.com/ru/post/163663/\n",
    "    #convert image -colorspace gray image\n",
    "    img = Image.open(image).convert('L')\n",
    "    img.save(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd22760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exif import Image as exif\n",
    "\n",
    "def get_focus_from_exif(f):\n",
    "    with open(f, \"rb\") as palm_1_file:\n",
    "        palm_1_image = exif(palm_1_file)\n",
    "    if palm_1_image.has_exif:\n",
    "        focal = palm_1_image.get('focal_length_in_35mm_film', 'Unknown')\n",
    "        digital_zoom = palm_1_image.get('digital_zoom_ratio', 'Unknown')  #–ø–æ–∏–≥—Ä–∞–µ–º —Å –∑—É–º–æ–º....–∞ –Ω–µ—Ç. –∑—É–º –Ω–∞—á–∏–Ω–∞–µ—Ç –º–µ–Ω—è—Ç—å —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∏ –æ–Ω –Ω–µ –Ω—É–∂–µ–Ω, –Ω–æ –ø—É—Å—Ç—å –±—É–¥–µ—Ç –ø–æ–∫–∞.\n",
    "    else:\n",
    "        focal = 0\n",
    "        digital_zoom = 1\n",
    "    \n",
    "    return focal, digital_zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dcf5309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert heic_to_jpg. inputs the source file and the path to the new file, returns the path to the new file\n",
    "def conv_heic_to_jpg(file, new_name):\n",
    "\n",
    "    heif_file = pillow_heif.read_heif(file)\n",
    "    image = Image.frombytes(\n",
    "        heif_file.mode,\n",
    "        heif_file.size,\n",
    "        heif_file.data,\n",
    "        \"raw\",\n",
    "    )\n",
    "\n",
    "    ex = heif_file.info['exif']\n",
    "    image.save(new_name, format(\"jpeg\"), exif=ex)\n",
    "    image.close()\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9555b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recognizing a file and retrieving data from it using a central number\n",
    "def res(file, show_pandas = 0):\n",
    "    if '.heic' in file:\n",
    "        temp_file = 'tmp.jpg'  #–Ω—É–∂–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ä—Ç–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç\n",
    "        file = conv_heic_to_jpg(work_file, temp_file)\n",
    "    \n",
    "    im = Image.open(file)\n",
    "    (width, height) = im.size\n",
    "    \n",
    "    results = model(file)\n",
    "    pd = results.pandas().xyxy[0]\n",
    " \n",
    "    pd = pd.loc[pd['name'] == 'znak'] # sign table\n",
    "    \n",
    "    # We don't need all the rooms. We only need the one closest to the center\n",
    "\n",
    "    # PROCESSING SIGNS\n",
    "    if show_pandas == 1:\n",
    "        print('–ó–Ω–∞–∫–∏\\n',pd)\n",
    "    \n",
    "    pd = pd.assign(to_centre_x = abs(width/2 - (pd.xmin + (pd.xmax-pd.xmin)/2)))     #consider the distance to the center\n",
    "    pd = pd.assign(centre_x = pd.xmin + (pd.xmax-pd.xmin)/2)                         #we calculate the coordinates of the center \n",
    "    \n",
    "    pd = pd.assign(width = pd.xmax - pd.xmin)                                        #width\n",
    "    pd = pd.assign(height = pd.ymax - pd.ymin)                                       #height\n",
    "    pd = pd.assign(s2 = pd.width * pd.height)                                        #area\n",
    "    \n",
    "    pd = pd.sort_values(['to_centre_x'] )                                            #we sort by proximity to the center. We need the closest number\n",
    "    \n",
    "    \n",
    "    d = dict()   # this dictionary will contain all the results\n",
    "    for index, row in pd.iterrows():\n",
    "        d ['width']  = row['width']\n",
    "        d ['height']  = row['height']\n",
    "        d ['s2']  = row['s2']\n",
    "        d ['xmin']  = row['xmin']\n",
    "        d ['ymin']  = row['ymin']\n",
    "        d ['xmax']  = row['xmax']\n",
    "        d ['ymax']  = row['ymax']\n",
    "        break\n",
    "    # Now in d are all the characteristics of the sign. \n",
    "    \n",
    "    d['im_width'] = width\n",
    "    d['im_height'] = height\n",
    "    \n",
    "    return d    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "41ae49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# procedure cuts out the sign, just to see what is found there. I needed it for debugging.\n",
    "# input a file, and a dictionary with data about the sign\n",
    "# WARNING: it will spoil the file it finds.\n",
    "\n",
    "def crop_znak(temp_file,znak):\n",
    "    if len(znak) <= 3:\n",
    "        #print('–Ω–µ —Å–º–æ–≥ –∫—Ä–æ–æ–ø–Ω—É—Ç—å', temp_file)\n",
    "        return\n",
    "    img = Image.open(temp_file)\n",
    "    xmin  = znak['xmin']\n",
    "    ymin = znak['ymin']\n",
    "    xmax  = znak['xmax']\n",
    "    ymax  = znak['ymax']\n",
    "    —Åentre_x = xmin + (xmax-xmin)/2\n",
    "    —Åentre_y = ymin + (ymax-ymin)/2\n",
    "    w_max = max(xmax-xmin, ymax-ymin)/2\n",
    "    #print((xmin, ymin,xmax, ymax))\n",
    "    img = img.crop((—Åentre_x-w_max, —Åentre_y-w_max,—Åentre_x+w_max, —Åentre_y+w_max))\n",
    "    img = img.resize((640,640))\n",
    "    print('—Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ ',temp_file)\n",
    "    img.save(temp_file)\n",
    "    #—Å—á–∏—Ç–∞–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫—Ä–æ–ø\n",
    "    k = znak['width']/640\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8721cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out the area around the sign to feed it back into the network for more accurate recognition. \n",
    "def mini_pic(temp_file,znak):\n",
    "    if len(znak) == 3:\n",
    "        print('–Ω–µ —Å–º–æ–≥ –∫—Ä–æ–æ–ø–Ω—É—Ç—å', temp_file)\n",
    "        return\n",
    "    if znak['width'] > 400: # only if the sign is very small\n",
    "        return\n",
    "    \n",
    "    img = Image.open(temp_file)\n",
    "    xmin  = znak['xmin']\n",
    "    ymin = znak['ymin']\n",
    "    xmax  = znak['xmax']\n",
    "    ymax  = znak['ymax']\n",
    "    centre_x = xmin + (xmax - xmin)/2\n",
    "    centre_y = ymin + (ymax - ymin)/2\n",
    "    #print((xmin, ymin,xmax, ymax))\n",
    "    img = img.crop((centre_x-480, centre_y - 480,centre_x+480, centre_y + 480))\n",
    "    img.save(temp_file)\n",
    "    #print('–º–∏–Ω–∏–ø–∏–∫',temp_file,centre_x,centre_y, znak['width'])\n",
    "    \n",
    "# try to cut out the area around the sign to feed it back to the network for more accurate recognition.  \n",
    "# This is if the sign in the photo is small and it did not find anything at all. do a cropped center 960x960\n",
    "def zoom960(temp_file):\n",
    "    \n",
    "    img = Image.open(temp_file)\n",
    "    w,h = img.size\n",
    "    centre_x = w//2\n",
    "    centre_y = h//2\n",
    "    img = img.crop((centre_x-480, centre_y - 480,centre_x+480, centre_y + 480))\n",
    "    img.save(temp_file)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "21a17e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we correct the sign: depending on the ratio between the found sides we find the angle and use it to calculate what 520 has become\n",
    "    \n",
    "from math import atan, sin, cos, tan,degrees\n",
    "\n",
    "def correct_znak2(znak):\n",
    "    \n",
    "    w_znak = 529 #—à–∏—Ä–∏–Ω–∞ –∑–Ω–∞–∫–∞ –≤ –º–º\n",
    "    h_znak = 112\n",
    "    if len(znak) == 3: #–ø–æ—Ö–æ–∂–µ, —á—Ç–æ –Ω–µ —Ä–∞–∞—Å–ø–æ–∑–Ω–∞–ª—Å—è\n",
    "        return w_znak\n",
    "    #—Å–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —É–≥–æ–ª –Ω–∞–∫–ª–æ–Ω–∞ –∑–Ω–∞–∫–∞ –ø–æ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—é —Å—Ç–æ—Ä–æ–Ω\n",
    "    HW  = 112/520 #—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –º–µ–∂–¥—É —Å—Ç–æ—Ä–æ–Ω–∞–º–∏\n",
    "    hw = znak['height']/znak['width']#–Ω–∞–π–¥–µ–Ω–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—â–µ–Ω–∏–µ –º–µ–∂–¥—É —Å—Ç–æ—Ä–æ–Ω–∞–º–∏\n",
    "    tan_alfa = -(HW - hw) / (1 - HW * hw)\n",
    "    alfa_rad = abs(math.atan(tan_alfa)) #–Ω–∞—à–ª–∏ —É–≥–æ–ª –Ω–∞–∫–ª–æ–Ω–∞ –∑–Ω–∞–∫–∞ –≤ —Ä–∞–¥–∏–∞–Ω–∞—Ö\n",
    "    print('–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤–µ—Ä–Ω—É—Ç–æ',degrees(alfa_rad))\n",
    "    \n",
    "    new_AB = w_znak * cos(alfa_rad) + h_znak * sin(alfa_rad)\n",
    "    #new_w = (CD-AB/tan(alfa_rad)) / (sin(alfa_rad) - cos(alfa_rad)*cos(alfa_rad)/sin(alfa_rad))\n",
    "    \n",
    "    print('–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª–∏–Ω—ã –∑–Ω–∞–∫–∞','520', '---->',new_AB)\n",
    "    \n",
    "    return new_AB\n",
    "\n",
    "\n",
    "#—Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è, –æ–Ω–∞ –∫–æ—Ä—Ä–µ—Ç–∫–∏—Ä—É–µ—Ç –Ω–µ 520, –∞ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —à–∏—Ä–∏–Ω—ã —É–º–µ–Ω—å—à–∞–µ—Ç.\n",
    "# def correct_znak(znak):\n",
    "#     if len(znak) == 3: #–ø–æ—Ö–æ–∂–µ, —á—Ç–æ –Ω–µ —Ä–∞–∞—Å–ø–æ–∑–Ω–∞–ª—Å—è\n",
    "#         return znak\n",
    "#     #—Å–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —É–≥–æ–ª –Ω–∞–∫–ª–æ–Ω–∞ –∑–Ω–∞–∫–∞ –ø–æ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—é —Å—Ç–æ—Ä–æ–Ω\n",
    "#     HW  = 112/520 #—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –º–µ–∂–¥—É —Å—Ç–æ—Ä–æ–Ω–∞–º–∏\n",
    "#     hw = znak['height']/znak['width']#–Ω–∞–π–¥–µ–Ω–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—â–µ–Ω–∏–µ –º–µ–∂–¥—É —Å—Ç–æ—Ä–æ–Ω–∞–º–∏\n",
    "#     tan_alfa = -(HW - hw) / (1 - HW * hw)\n",
    "#     alfa_rad = math.atan(tan_alfa) #–Ω–∞—à–ª–∏ —É–≥–æ–ª –Ω–∞–∫–ª–æ–Ω–∞ –∑–Ω–∞–∫–∞ –≤ —Ä–∞–¥–∏–∞–Ω–∞—Ö\n",
    "#     print('–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤–µ—Ä–Ω—É—Ç–æ',degrees(alfa_rad))\n",
    "    \n",
    "#     CD = znak['height']\n",
    "#     AB = znak['width']\n",
    "#     new_w = (CD-AB/tan(alfa_rad)) / (sin(alfa_rad) - cos(alfa_rad)*cos(alfa_rad)/sin(alfa_rad))\n",
    "    \n",
    "#     print('–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª–∏–Ω—ã –∑–Ω–∞–∫–∞',znak['width'], '---->',new_w)\n",
    "#     znak['width'] = new_w\n",
    "#     return znak\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6a1e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS FUNCTION SEARCHES THE DISTANCE BETWEEN TWO fixing points on a number and returns it in pixels\n",
    "\n",
    "def res2(file, show_pandas = 0):\n",
    "#     if '.heic' in file:\n",
    "#         temp_file = 'tmp.jpg'  #–Ω—É–∂–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ä—Ç–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç\n",
    "#         file = conv_heic_to_jpg(work_file,temp_file)\n",
    "    \n",
    "    im = Image.open(file)\n",
    "    (width, height) = im.size\n",
    "    \n",
    "    results = model2(file)\n",
    "    pd = results.pandas().xyxy[0]\n",
    " \n",
    "    pd = pd.loc[pd['name'] == 'znak']                   # sign table\n",
    "    \n",
    "    #–≤—Å–µ –Ω–æ–º–µ—Ä–∞ –Ω–∞–º –Ω–µ –Ω–∞–¥–æ. –ù–∞–º –Ω–∞–¥–æ —Ç–æ–ª—å–∫–æ —Ç–æ—Ç, —á—Ç–æ –±–ª–∏–∂–µ –∫ —Ü–µ–Ω—Ç—Ä—É\n",
    "\n",
    "    #–û–ë–†–ê–ë–ê–¢–´–í–ê–ï–ú —Ç–æ—á–∫–∏ –Ω–∞ –∑–Ω–∞–∫–µ\n",
    "    if show_pandas == 1:\n",
    "        print('–ó–Ω–∞–∫–∏\\n',pd)\n",
    "    \n",
    "    pd = pd.assign(centre_x = pd.xmin + (pd.xmax-pd.xmin)/2)                         #—Å—á–∏—Ç–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ü–µ–Ω—Ç—Ä–∞ \n",
    "    pd = pd.assign(centre_y = pd.ymin + (pd.ymax-pd.ymin)/2)                         #—Å—á–∏—Ç–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ü–µ–Ω—Ç—Ä–∞ \n",
    "    \n",
    "    pd = pd.assign(width = pd.xmax - pd.xmin)                                        #—à–∏—Ä–∏–Ω–∞\n",
    "    pd = pd.assign(height = pd.ymax - pd.ymin)                                       #–≤—ã—Å–æ—Ç–∞\n",
    "    \n",
    "    pd = pd.loc[pd['centre_y'] >280]\n",
    "    pd = pd.loc[pd['centre_y'] <380]\n",
    "    \n",
    "    pd = pd.sort_values(['centre_x'] )                                            #—Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –±–ª–∏–∑–æ—Å—Ç–∏ –∫ —Ü–µ–Ω—Ç—Ä—É. –ù–∞–º –Ω–∞–¥–æ —Å–∞–º—ã–π –±–ª–∏–∑–∫–∏–π –Ω–æ–º–µ—Ä\n",
    "    \n",
    "    if show_pandas == 1:\n",
    "        print('–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ\\n',pd)\n",
    "    d = []   #–≤ —ç—Ç–æ–º –±—É–¥—É—Ç –¥–≤–µ —Ç–æ—á–∫–∏, –Ω–∞–º –Ω–∞–¥–æ –Ω–∞–π—Ç–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –Ω–∏–º–∏\n",
    "    for index, row in pd.iterrows():\n",
    "        d.append([row['centre_x'],row['centre_y']])\n",
    "    if len(d) == 2:\n",
    "        r = ((d[0][0] - d[1][0])**2 + (d[0][1] - d[1][1])**2) **0.5\n",
    "    else:\n",
    "        r = 0\n",
    "         \n",
    "    if show_pandas == 1:\n",
    "        print('–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ', r)\n",
    "    \n",
    "    return r    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94a00787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–Ω–∞–∫–∏\n",
      "          xmin        ymin        xmax        ymax  confidence  class  name\n",
      "0  614.981262  300.257507  627.810974  313.202515    0.737279      0  znak\n",
      "1   14.071442  325.275391   27.708603  339.688538    0.722411      0  znak\n",
      "–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ\n",
      "          xmin        ymin        xmax        ymax  confidence  ...  name    centre_x    centre_y      width     height\n",
      "1   14.071442  325.275391   27.708603  339.688538    0.722411  ...  znak   20.890022  332.481964  13.637161  14.413147\n",
      "0  614.981262  300.257507  627.810974  313.202515    0.737279  ...  znak  621.396118  306.730011  12.829712  12.945007\n",
      "\n",
      "[2 rows x 11 columns]\n",
      "–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ 601.0580124133401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "601.0580124133401"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2('Y:\\\\img_1931.jpg',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e4178282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_recognition(f):\n",
    "    w_znak = 520 #—à–∏—Ä–∏–Ω–∞ –∑–Ω–∞–∫–∞ –≤ –º–º\n",
    "    #w = 4032    #—Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã/—Ñ–æ—Ç–æ –≤ –ø–∏–∫—Å–µ–ª—è—Ö\n",
    "    \n",
    "    name = f[f.rfind('/')+1:]\n",
    "    work_file = f\n",
    "    temp_file = 'temp.jpg'\n",
    "    #temp_file = 'Y:/'+name\n",
    "    if '.heic' in f:\n",
    "        temp_file = 'Y:/'+name.replace('.heic','.jpg')\n",
    "        print('–ù–æ–≤–æ–µ –∏–º—è',temp_file)\n",
    "        work_file = conv_heic_to_jpg(work_file,temp_file)\n",
    "        #print('–°–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤',work_file)\n",
    "    focus, digital_zoom = get_focus_from_exif(work_file)\n",
    "    print('focus, digital_zoom',focus, digital_zoom)\n",
    "     \n",
    "    img = Image.open(work_file)\n",
    "    img = exif_transpose(img)\n",
    "    w,h = img.size\n",
    "    img.save(temp_file)\n",
    "    \n",
    "    img.close()\n",
    "\n",
    "    #get_grayscale2(temp_file)  #–ø—ã—Ç–∞–ª—Å—è —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Å–µ—Ä—ã–º. –Ω–µ –æ—á–µ–Ω—å.\n",
    "    \n",
    "    znak1 = res(temp_file)\n",
    "    znak = znak1\n",
    "    \n",
    "#     #–ó–∞—Ö–æ–¥–∏–º –µ—â–µ 1 —Ä–∞–∑, –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏. –ø—Ä–æ—Å—Ç–æ –Ω–∞ —É–¥–∞—á—É\n",
    "#     if len(znak) <= 3:\n",
    "#         zoom960(temp_file)\n",
    "#         znak1 = res(temp_file)\n",
    "#         znak = znak1\n",
    "        \n",
    "    \n",
    "    \n",
    "    #–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢\n",
    "#     if len(znak1) <= 3:\n",
    "#         print('–§–ê–ô–õ –ù–ï –†–ê–°–ü–û–ó–ù–ê–ù', f)\n",
    "#         not_recognize.append(f) \n",
    "#         return 0.0\n",
    "    \n",
    "#     #–ø—Ä–æ–±—É–µ–º –≤—ã—Ä–µ–∑–∞—Ç—å –æ–±–ª–∞—Å—Ç—å,—á—Ç–æ–±—ã –∑–Ω–∞–∫ –±—ã–ª –±–ª–ª–∏–∂–µ. –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏–∫—Å–µ–ª–µ–π –æ—Ç —ç—Ç–æ–≥–æ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è\n",
    "#     print('—à–∏—Ä–∏–Ω–∞ –¥–æ –º–∏–Ω–∏ –ø–∏–∫–∞', znak1['width'])\n",
    "\n",
    "#     mini_pic(temp_file,znak1)\n",
    "#     #–≤—ã—Ä–µ–∑–∞–ª–∏ –∏ –µ—â–µ —Ä–∞–∑ –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ\n",
    "#     znak = res(temp_file)\n",
    "#     if len(znak) != 3:\n",
    "#         print('—à–∏—Ä–∏–Ω–∞ –ø–æ—Å–ª–µ –º–∏–Ω–∏ –ø–∏–∫–∞', znak['width'], '—É—Ç–æ—á–Ω–µ–Ω–∏–µ', znak1['width']-znak['width'])\n",
    "#     else: #–ø–æ—á–µ–º—É —Ç–æ –ø–æ—Å–ª–µ –∑—É–º–∞, –∑–Ω–∞–∫ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª—Å—è. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ, —á—Ç–æ –±—ã–ª–æ, —ç—Ç–æ –≤—Å—è–∫–æ –ª—É—á—à–µ —á–µ–º –Ω–æ–ª—å\n",
    "#         znak = znak1\n",
    "        \n",
    "    #....–∫–æ–Ω–µ—Ü —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞.\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    w_matrix = 35# 34.974 #—à–∏—Ä–∏–Ω–∞ –º–∞—Ç—Ä–∏—Ü—ã –≤ –º–º. –í—Ä–æ–¥–µ –±—ã –∏–º–µ–Ω–Ω—å —ç—Ç–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è —à–∏—Ä–∏–Ω–∞, –Ω–æ –µ–µ –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–µ –ø—Ä–æ—Å—Ç–æ –æ–∫—Ä—É–≥–ª—è—é—Ç –¥–æ 35 –º–º.\n",
    "    #print('—à–∏—Ä–∏–Ω–∞ –∫–∞–¥—Ä–∞',w)\n",
    "    pixel_in_mm = w/w_matrix\n",
    "    d1 = 0\n",
    "    if 'width' in znak:\n",
    "        k = crop_znak(temp_file,znak)  #–∫–æ—ç—Ñ—Ñ–∏–∫–∏–µ–Ω—Ç –∫—Ä–æ–ø–∞\n",
    "        r = res2(temp_file) #–ø–æ–ª—É—á–∏–ª–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–æ—á–∫–∞–º–∏ –Ω–∞ –Ω–æ–º–µ—Ä–µ \n",
    "        print('r,k',r* k,znak['width'])\n",
    "        if r!=0:\n",
    "            r = r * k #–ø—Ä–∏–≤–µ–ª–∏ –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π —à–∏—Ä–∏–Ω–µ\n",
    "            #print(r)\n",
    "            d1 = (1 + 487 /(r/pixel_in_mm))* focus/1000\n",
    "            print('—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ —Ç–æ—á–∫–∞–º', d1)\n",
    "            return d1 #–µ—Å–ª–∏ –µ—Å—Ç—å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏ - –∑–∞ –Ω–∏–º –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ\n",
    "    \n",
    "    \n",
    "    if len(znak) <= 3:\n",
    "        print('–§–ê–ô–õ –ù–ï –†–ê–°–ü–û–ó–ù–ê–ù', f)\n",
    "        not_recognize.append(f)\n",
    "        d = 0.0\n",
    "    #—Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∑–Ω–∞–∫–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ csv\n",
    "    else:\n",
    "         #—É—Ç–æ—á–Ω–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ\n",
    "        w_znak = correct_znak2(znak)\n",
    "        d = (1 + w_znak /(znak['width']/pixel_in_mm))* focus/1000  #–Ω—É –≤–æ—Ç —Ç—É—Ç —è –∑–∞–º–æ—Ä–æ—á–∏–ª—Å—è. –Ω–µ –º–æ–≥ —Ä–µ—à–∏—Ç—å –¥–æ —á–µ–≥–æ —Å—á–∏—Ç–∞—Ç—å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ - –¥–æ –æ–ø—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ü–µ–Ω—Ç—Ä–∞ –∏–ª–∏ –¥–æ –º–∞—Ç—Ä–∏—Ü—ã. –°—Ç–∞–ª —Å—á–∏—Ç–∞—Ç—å –¥–æ –º–∞—Ç—Ä–∏—Ü—ã. –û–±—ä–µ–∫—Ç–∏–≤ –º–æ–∂–µ—Ç –≥—É–ª—è—Ç—å –æ—Ç –º–∞—Ç—Ä–∏—Ü—ã –Ω–∞ –º–Ω–æ–≥–æ —Å–º.\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6210b18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381 —Ä–∞–±–æ—Ç–∞–µ–º  —Å —Ñ–∞–π–ª–æ–º:  ..\\data_set\\test\\img_2674.heic\n",
      "–ù–æ–≤–æ–µ –∏–º—è Y:\\img_2674.jpg\n",
      "focus, digital_zoom 14 1.0327868852459017\n",
      "–§–ê–ô–õ –ù–ï –†–ê–°–ü–û–ó–ù–ê–ù ..\\data_set\\test\\img_2674.heic\n",
      "–ó–∞–ø–∏—Å–∞–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç:  img_2674.heic;0.0\n",
      "\n",
      "\n",
      "\n",
      "382 —Ä–∞–±–æ—Ç–∞–µ–º  —Å —Ñ–∞–π–ª–æ–º:  ..\\data_set\\test\\img_2675.jpg\n",
      "focus, digital_zoom 14 1.0223123732251522\n",
      "—Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤  temp.jpg\n",
      "r,k 148.69137140255333 158.6239013671875\n",
      "—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ —Ç–æ—á–∫–∞–º 5.296307860848156\n",
      "–ó–∞–ø–∏—Å–∞–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç:  img_2675.jpg;5.296307860848156\n",
      "\n",
      "\n",
      "\n",
      "383 —Ä–∞–±–æ—Ç–∞–µ–º  —Å —Ñ–∞–π–ª–æ–º:  ..\\data_set\\test\\img_2676.jpg\n",
      "focus, digital_zoom 14 1.0223123732251522\n",
      "—Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤  temp.jpg\n",
      "r,k 189.8632736006027 206.633056640625\n",
      "—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ —Ç–æ—á–∫–∞–º 4.150837973478968\n",
      "–ó–∞–ø–∏—Å–∞–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç:  img_2676.jpg;4.150837973478968\n",
      "\n",
      "\n",
      "\n",
      "384 —Ä–∞–±–æ—Ç–∞–µ–º  —Å —Ñ–∞–π–ª–æ–º:  ..\\data_set\\test\\img_2677.heic\n",
      "–ù–æ–≤–æ–µ –∏–º—è Y:\\img_2677.jpg\n",
      "focus, digital_zoom 14 1.0327868852459017\n",
      "—Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤  Y:\\img_2677.jpg\n",
      "r,k 139.3193845650131 157.6392822265625\n",
      "—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ —Ç–æ—á–∫–∞–º 5.651647642876854\n",
      "–ó–∞–ø–∏—Å–∞–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç:  img_2677.heic;5.651647642876854\n",
      "\n",
      "\n",
      "\n",
      "385 —Ä–∞–±–æ—Ç–∞–µ–º  —Å —Ñ–∞–π–ª–æ–º:  ..\\data_set\\test\\img_2677.jpg\n",
      "focus, digital_zoom 14 1.0223123732251522\n",
      "—Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤  temp.jpg\n",
      "r,k 225.94761113157276 239.9176025390625\n",
      "—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ —Ç–æ—á–∫–∞–º 3.490175720851636\n",
      "–ó–∞–ø–∏—Å–∞–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç:  img_2677.jpg;3.490175720851636\n",
      "\n",
      "\n",
      "\n",
      "–Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ —Ñ–∞–π–ª–æ–≤ 1\n",
      "–Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ ..\\data_set\\test\\img_2674.heic\n",
      "—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤  ..\\data_set\\sample_solution.csv\n",
      "–û—à–∏–±–∫–∞ –Ω–µ –ø–æ—Å—á–∏—Ç–∞–Ω–∞. –ò—Å—Ç–∏–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ. –î–∞—Ç–∞—Å–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π?\n"
     ]
    }
   ],
   "source": [
    "train_csv = '../data_set/train.csv'  #data set if you run it on a training dataset, it will be considered an error.\n",
    "keys = ['width', 'height', 's2', 'xmin', 'ymin', 'xmax', 'ymax','im_width', 'im_height']\n",
    "pic_data = '../data_set/train'  # here is the dataset\n",
    "pic_data_test  = pic_data\n",
    "\n",
    "# TO RUN ON YOUR DATASET, YOU NEED TO CHANGE THIS PATH\n",
    "pic_data_test = '../data_set/test'  # Here is the test dataset\n",
    "\n",
    "\n",
    "test = '../data_set/sample_solution.csv'  # the result will be recorded here\n",
    "\n",
    "# first read all the distances given to us from the training dataset\n",
    "dist = dict()  # here we will store all distances extracted from the file. In the form of a dictionary\n",
    "with open(train_csv, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.replace('\\n','')\n",
    "        key, d = line.split(';')\n",
    "        dist[key] = d\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "new_f = 'image_name;distance'\n",
    "not_recognize = []  # there will be some unrecognized\n",
    "n = 0\n",
    "abs_mistake, otn_mistake, vsego = 0, 0, 0  # To calculate the error\n",
    "for f in os.listdir(pic_data_test):\n",
    "    n +=1\n",
    "    if n<= 380:\n",
    "        continue\n",
    "    if n>385:\n",
    "         break\n",
    "    \n",
    "    \n",
    "    work_file = os.path.join(pic_data_test, f)\n",
    "    print(n, 'working with the file: ', work_file)\n",
    "\n",
    "    itog = file_recognition(work_file)\n",
    "    \n",
    "    # we get the true value, count the error\n",
    "    if f in dist:\n",
    "        y = float(dist[f])\n",
    "        mistake = (y - itog) / y # I apologize for not using your mistake, but it makes more sense to me in percentages, and since I don't train on a mistake, I did so.\n",
    "        print('Error', mistake, 'estimation', y, '–ø—Ä–µ–¥—Å–∫', itog)\n",
    "        otn_mistake += mistake  #you need it to see if it goes in the plus or minus\n",
    "        abs_mistake += abs(mistake)\n",
    "        vsego +=1\n",
    "    \n",
    "    \n",
    "    st = f+';' + str(itog)\n",
    "    print('Recorded result: ',st)\n",
    "    print('\\n\\n')    \n",
    "    new_f = new_f +'\\n'+st\n",
    "    \n",
    "#print(new_f)\n",
    "with open(test, 'w', encoding = 'utf-8') as file:\n",
    "    file.write(new_f)\n",
    "print('Nr of files not detected:', len(not_recognize))\n",
    "print('unrecognized:', *not_recognize)\n",
    "print('saved in:', test)\n",
    "if vsego != 0:\n",
    "    print('–êbsolute error', round(abs_mistake/vsego*100, 5))\n",
    "    print('Relative error', round(otn_mistake/vsego*100, 5))\n",
    "else:\n",
    "    print('No error has been calculated. No true data detected. Is the dataset a test one?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47601b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–Ω–∞–∫–∏\n",
      "           xmin         ymin         xmax         ymax  confidence  class  name\n",
      "0  1760.632202  1313.192139  2381.237305  1438.997437    0.952805      0  znak\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'width': 620.6051025390625,\n",
       " 'height': 125.8052978515625,\n",
       " 's2': 78075.40977312624,\n",
       " 'xmin': 1760.6322021484375,\n",
       " 'ymin': 1313.192138671875,\n",
       " 'xmax': 2381.2373046875,\n",
       " 'ymax': 1438.9974365234375,\n",
       " 'im_width': 3968,\n",
       " 'im_height': 2976}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res('Y:\\\\255_1.jpg',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2b62a3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ù–æ–≤–æ–µ –∏–º—è Y:\\img_2674.jpg\n",
      "focus, digital_zoom 14 1.0327868852459017\n",
      "–§–ê–ô–õ –ù–ï –†–ê–°–ü–û–ó–ù–ê–ù ..\\data_set\\test\\img_2674.heic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_recognition('..\\\\data_set\\\\test\\\\img_2674.heic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7b99d5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "focus, digital_zoom 27 1.0\n",
      "—Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤  temp.jpg\n",
      "r,k 592.7320572254057 619.9266357421875\n",
      "—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ —Ç–æ—á–∫–∞–º 2.5419996463221812\n",
      "2.5419996463221812\n",
      "\n",
      "\n",
      "focus, digital_zoom 31 1.0\n",
      "—Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤  temp.jpg\n",
      "r,k 718.0005061784991 743.150390625\n",
      "—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ —Ç–æ—á–∫–∞–º 2.414798399046464\n",
      "2.414798399046464\n",
      "\n",
      "\n",
      "focus, digital_zoom 52 1.0\n",
      "—Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤  temp.jpg\n",
      "r,k 1166.430252539312 1251.6114501953125\n",
      "—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ —Ç–æ—á–∫–∞–º 2.513371394382705\n",
      "2.513371394382705\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(file_recognition('Y:\\\\255_1.jpg'))\n",
    "\n",
    "print('\\n')\n",
    "print(file_recognition('Y:\\\\255_2.jpg'))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(file_recognition('Y:\\\\255_3.jpg'))\n",
    "\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a599ca39",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Y:\\\\421_1.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [160]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfile_recognition\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mY:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m421_1.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(file_recognition(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m421_2.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Input \u001b[1;32mIn [154]\u001b[0m, in \u001b[0;36mfile_recognition\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m     12\u001b[0m     work_file \u001b[38;5;241m=\u001b[39m conv_heic_to_jpg(work_file,temp_file)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m#print('–°–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤',work_file)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m focus, digital_zoom \u001b[38;5;241m=\u001b[39m \u001b[43mget_focus_from_exif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwork_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfocus, digital_zoom\u001b[39m\u001b[38;5;124m'\u001b[39m,focus, digital_zoom)\n\u001b[0;32m     17\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(work_file)\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mget_focus_from_exif\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m  \u001b[38;5;21mget_focus_from_exif\u001b[39m(f):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m palm_1_file:\n\u001b[0;32m      4\u001b[0m         palm_1_image \u001b[38;5;241m=\u001b[39m exif(palm_1_file)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m palm_1_image\u001b[38;5;241m.\u001b[39mhas_exif:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Y:\\\\421_1.jpg'"
     ]
    }
   ],
   "source": [
    "print(file_recognition('Y:\\\\421_1.jpg'))\n",
    "print('\\n')\n",
    "print(file_recognition('Y:\\\\421_2.jpg'))\n",
    "print('\\n')\n",
    "\n",
    "print(file_recognition('Y:\\\\421_3.jpg'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "752fc870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.923146672370446\n",
      "\n",
      "\n",
      "4.690990338609638\n",
      "\n",
      "\n",
      "4.974977451052313\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(file_recognition('Y:\\\\490_1.jpg'))\n",
    "print('\\n')\n",
    "print(file_recognition('Y:\\\\490_2.jpg'))\n",
    "print('\\n')\n",
    "\n",
    "print(file_recognition('Y:\\\\490_3.jpg'))\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
